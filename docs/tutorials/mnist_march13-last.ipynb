{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sathvik-Ravula/QuantumNN/blob/main/docs/tutorials/mnist_march13-last.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X35qHdh5Gzqg"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TorxE5tnkvb2"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.15.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxkQA6oblNqI"
      },
      "source": [
        "Install TensorFlow Quantum:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saFHsRDpkvkH"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-quantum==0.7.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ql5PW-ACO0J"
      },
      "outputs": [],
      "source": [
        "# Update package resources to account for version changes.\n",
        "import importlib, pkg_resources\n",
        "\n",
        "importlib.reload(pkg_resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdgMMZEBGqyl"
      },
      "source": [
        "Now import TensorFlow and the module dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enZ300Bflq80"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "\n",
        "import cirq\n",
        "import sympy\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import collections\n",
        "\n",
        "# visualization tools\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from cirq.contrib.svg import SVGCircuit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b08Mmbs8lr81"
      },
      "source": [
        "## 1. Load the data\n",
        "\n",
        "In this tutorial you will build a binary classifier to distinguish between the digits 3 and 6, following <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> This section covers the data handling that:\n",
        "\n",
        "- Loads the raw data from Keras.\n",
        "- Filters the dataset to only 3s and 6s.\n",
        "- Downscales the images so they fit can fit in a quantum computer.\n",
        "- Removes any contradictory examples.\n",
        "- Converts the binary images to Cirq circuits.\n",
        "- Converts the Cirq circuits to TensorFlow Quantum circuits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDUdGxn-ojgy"
      },
      "source": [
        "### 1 Load the raw data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HERE IS THE ADAPTATION FOR CRACK DETECTION DATASET"
      ],
      "metadata": {
        "id": "c-RmkUxl8NdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cirq\n",
        "import collections\n",
        "import os\n",
        "\n",
        "# Define dataset paths\n",
        "train_dir = \"/content/dataset/train\"  # Treat 'val' as training data\n",
        "val_dir = \"/content/dataset/val\"\n",
        "test_dir = \"/content/dataset/test\"\n",
        "\n",
        "# Load images from directory\n",
        "def load_images(directory, image_size=(28, 28), batch_size=32):\n",
        "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        directory,\n",
        "        image_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        color_mode='grayscale',  # Since original MNIST is grayscale\n",
        "        shuffle=True\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "# Load training and testing datasets\n",
        "train_dataset = load_images(train_dir)\n",
        "test_dataset = load_images(val_dir)\n",
        "val_dataset = load_images(test_dir)\n",
        "\n",
        "# Function to normalize images\n",
        "def preprocess_image(image, label):\n",
        "    image = tf.image.resize(image, (4, 4))  # Resize to (4,4)\n",
        "    image = image / 255.0  # Normalize to [0,1]\n",
        "    return image, label\n",
        "\n",
        "# Apply preprocessing\n",
        "train_dataset = train_dataset.map(preprocess_image)\n",
        "test_dataset = val_dataset.map(preprocess_image)\n",
        "val_dataset = test_dataset.map(preprocess_image)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "x_train, y_train = [], []\n",
        "for img, lbl in train_dataset:\n",
        "    x_train.extend(img.numpy())\n",
        "    y_train.extend(lbl.numpy())\n",
        "\n",
        "x_val, y_val = [], []\n",
        "for img, lbl in train_dataset:\n",
        "    x_val.extend(img.numpy())\n",
        "    y_val.extend(lbl.numpy())\n",
        "\n",
        "x_test, y_test = [], []\n",
        "for img, lbl in test_dataset:\n",
        "    x_test.extend(img.numpy())\n",
        "    y_test.extend(lbl.numpy())\n",
        "\n",
        "x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "x_val, y_val = np.array(x_val), np.array(y_val)\n",
        "x_test, y_test = np.array(x_test), np.array(y_test)\n",
        "\n",
        "# Convert images to quantum circuits using Angle Encoding\n",
        "def convert_to_circuit(image):\n",
        "    \"\"\"Encodes image using Ry rotations ().\"\"\"\n",
        "    values = np.ndarray.flatten(image)\n",
        "    qubits = cirq.GridQubit.rect(4, 4)\n",
        "    circuit = cirq.Circuit()\n",
        "    for i, value in enumerate(values):\n",
        "        theta = np.pi * value  # Scale pixel intensity to rotation angle\n",
        "        circuit.append(cirq.ry(theta)(qubits[i]))\n",
        "    return circuit\n",
        "\n",
        "x_train_circ = [convert_to_circuit(x) for x in x_train]\n",
        "x_val_circ = [convert_to_circuit(x) for x in x_val]\n",
        "x_test_circ = [convert_to_circuit(x) for x in x_test]\n"
      ],
      "metadata": {
        "id": "TQPheLUZqy0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3POmUEUojhe",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "SVGCircuit(x_train_circ[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEQMxCcBojhg"
      },
      "source": [
        "Compare this circuit to the indices where the image value exceeds the threshold:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "THRESHOLD = 0.5\n",
        "\n",
        "x_train_bin = np.array(x_train > THRESHOLD, dtype=np.float32)\n",
        "x_val_bin = np.array(x_val > THRESHOLD, dtype=np.float32)\n",
        "x_test_bin = np.array(x_test > THRESHOLD, dtype=np.float32)"
      ],
      "metadata": {
        "id": "P4oKV4l3EzsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBIsiXdtojhh"
      },
      "outputs": [],
      "source": [
        "bin_img = x_train_bin[0, :, :, 0]\n",
        "indices = np.array(np.where(bin_img)).T\n",
        "indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWZ24w1Oojhk"
      },
      "source": [
        "Convert these `Cirq` circuits to tensors for `tfq`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZStEMk4ojhk"
      },
      "outputs": [],
      "source": [
        "x_train_tfcirc = tfq.convert_to_tensor(x_train_circ)\n",
        "x_val_tfcirc = tfq.convert_to_tensor(x_val_circ)\n",
        "x_test_tfcirc = tfq.convert_to_tensor(x_test_circ)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bUHR3cIVTKy6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4USiqeOqGL67"
      },
      "source": [
        "## 2. Quantum neural network\n",
        "\n",
        "There is little guidance for a quantum circuit structure that classifies images. Since the classification is based on the expectation of the readout qubit, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> propose using two qubit gates, with the readout qubit always acted upon. This is similar in some ways to running small a <a href=\"https://arxiv.org/abs/1511.06464\" class=\"external\">Unitary RNN</a> across the pixels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knIzawEeojho"
      },
      "source": [
        "### 2.1 Build the model circuit\n",
        "\n",
        "This following example shows this layered approach. Each layer uses *n* instances of the same gate, with each of the data qubits acting on the readout qubit.\n",
        "\n",
        "Start with a simple class that will add a layer of these gates to a circuit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hjxxgU5ojho"
      },
      "outputs": [],
      "source": [
        "class CircuitLayerBuilder():\n",
        "\n",
        "    def __init__(self, data_qubits, readout):\n",
        "        self.data_qubits = data_qubits\n",
        "        self.readout = readout\n",
        "\n",
        "    def add_layer(self, circuit, gate, prefix):\n",
        "        for i, qubit in enumerate(self.data_qubits):\n",
        "            symbol = sympy.Symbol(prefix + '-' + str(i))\n",
        "            circuit.append(gate(qubit, self.readout)**symbol)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjo5hANFojhr"
      },
      "source": [
        "Build an example circuit layer to see how it looks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzXWOpUGojhs"
      },
      "outputs": [],
      "source": [
        "demo_builder = CircuitLayerBuilder(data_qubits=cirq.GridQubit.rect(4, 1),\n",
        "                                   readout=cirq.GridQubit(-1, -1))\n",
        "\n",
        "circuit = cirq.Circuit()\n",
        "demo_builder.add_layer(circuit, gate=cirq.XX, prefix='xx')\n",
        "SVGCircuit(circuit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-QhPE1pojhu"
      },
      "source": [
        "Now build a two-layered model, matching the data-circuit size, and include the preparation and readout operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiALbpwRGL69"
      },
      "outputs": [],
      "source": [
        "def create_quantum_model():\n",
        "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
        "    data_qubits = cirq.GridQubit.rect(4, 4)  # a 4x4 grid.\n",
        "    readout = cirq.GridQubit(-1, -1)  # a single qubit at [-1,-1]\n",
        "    circuit = cirq.Circuit()\n",
        "\n",
        "    # Prepare the readout qubit.\n",
        "    circuit.append(cirq.X(readout))\n",
        "    circuit.append(cirq.H(readout))\n",
        "\n",
        "    builder = CircuitLayerBuilder(data_qubits=data_qubits, readout=readout)\n",
        "\n",
        "    # Then add layers (experiment by adding more).\n",
        "    builder.add_layer(circuit, cirq.XX, \"xx1\")\n",
        "    builder.add_layer(circuit, cirq.ZZ, \"zz1\")\n",
        "\n",
        "    # Finally, prepare the readout qubit.\n",
        "    circuit.append(cirq.H(readout))\n",
        "\n",
        "    return circuit, cirq.Z(readout)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cirq\n",
        "import sympy\n",
        "\n",
        "def create_better_quantum_model():\n",
        "    \"\"\"Create an improved QNN with more expressive layers and deeper entanglement.\"\"\"\n",
        "    data_qubits = cirq.GridQubit.rect(4, 4)  # 4x4 grid\n",
        "    readout = cirq.GridQubit(-1, -1)  # Readout qubit\n",
        "    circuit = cirq.Circuit()\n",
        "\n",
        "    # Prepare the readout qubit\n",
        "    circuit.append([cirq.X(readout), cirq.H(readout)])\n",
        "\n",
        "    # Introduce variational parameters\n",
        "    symbols = [sympy.Symbol(f'theta_{i}') for i in range(len(data_qubits) * 2)]\n",
        "\n",
        "    # Apply parameterized single-qubit rotations\n",
        "    for i, qubit in enumerate(data_qubits):\n",
        "        circuit.append(cirq.ry(symbols[i])(qubit))\n",
        "        circuit.append(cirq.rz(symbols[i + len(data_qubits)])(qubit))\n",
        "\n",
        "    # Apply multiple layers of entanglement (improves non-linearity)\n",
        "    for _ in range(3):  # Increase depth by repeating layers\n",
        "        circuit.append(cirq.XX(q1, q2) for q1, q2 in zip(data_qubits[:-1], data_qubits[1:]))\n",
        "        circuit.append(cirq.ZZ(q1, q2) for q1, q2 in zip(data_qubits[:-1], data_qubits[1:]))\n",
        "\n",
        "    # Final readout qubit preparation\n",
        "    circuit.append(cirq.H(readout))\n",
        "\n",
        "    return circuit, cirq.Z(readout)\n"
      ],
      "metadata": {
        "id": "s85B4P_CSRQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QZvVh7vojhx"
      },
      "outputs": [],
      "source": [
        "model_circuit, model_readout = create_quantum_model()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_circuit"
      ],
      "metadata": {
        "id": "L-I-42L5TOvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY7vbY6yfABE"
      },
      "source": [
        "### 2.2 Wrap the model-circuit in a tfq-keras model\n",
        "\n",
        "Build the Keras model with the quantum components. This model is fed the \"quantum data\", from `x_train_circ`, that encodes the classical data. It uses a *Parametrized Quantum Circuit* layer, `tfq.layers.PQC`, to train the model circuit, on the quantum data.\n",
        "\n",
        "To classify these images, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> proposed taking the expectation of a readout qubit in a parameterized circuit. The expectation returns a value between 1 and -1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYdf_KOxojh0"
      },
      "outputs": [],
      "source": [
        "# Build the Keras model.\n",
        "model = tf.keras.Sequential([\n",
        "    # The input is the data-circuit, encoded as a tf.string\n",
        "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
        "    # The PQC layer returns the expected value of the readout gate, range [-1,1].\n",
        "    tfq.layers.PQC(model_circuit, model_readout),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz-FbVc9ojh3"
      },
      "source": [
        "Next, describe the training procedure to the model, using the `compile` method.\n",
        "\n",
        "Since the the expected readout is in the range `[-1,1]`, optimizing the hinge loss is a somewhat natural fit.\n",
        "\n",
        "Note: Another valid approach would be to shift the output range to `[0,1]`, and treat it as the probability the model assigns to class `3`. This could be used with a standard a `tf.losses.BinaryCrossentropy` loss.\n",
        "\n",
        "To use the hinge loss here you need to make two small adjustments. First convert the labels, `y_train_nocon`, from boolean to `[-1,1]`, as expected by the hinge loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgMNkC1Fojh5"
      },
      "outputs": [],
      "source": [
        "y_train_hinge = 2.0 * y_train - 1.0\n",
        "y_val_hinge = 2.0 * y_val - 1.0\n",
        "y_test_hinge = 2.0 * y_test - 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nwnveDiojh7"
      },
      "source": [
        "Second, use a custiom `hinge_accuracy` metric that correctly handles `[-1, 1]` as the `y_true` labels argument.\n",
        "`tf.losses.BinaryAccuracy(threshold=0.0)` expects `y_true` to be a boolean, and so can't be used with hinge loss)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XKtZ_TEojh8"
      },
      "outputs": [],
      "source": [
        "def hinge_accuracy(y_true, y_pred):\n",
        "    y_true = tf.squeeze(y_true) > 0.0\n",
        "    y_pred = tf.squeeze(y_pred) > 0.0\n",
        "    result = tf.cast(y_true == y_pred, tf.float32)\n",
        "\n",
        "    return tf.reduce_mean(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlpETlLRojiA"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=tf.keras.losses.Hinge(),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[hinge_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"/content/quantum_model_weights-testacc98.h5\")"
      ],
      "metadata": {
        "id": "JIEWxP93TSxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkHq2RstojiC"
      },
      "outputs": [],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsuOzDYblA9s"
      },
      "source": [
        "### Train the quantum model\n",
        "\n",
        "Now train the modelâ€”this takes about 45 min. If you don't want to wait that long, use a small subset of the data (set `NUM_EXAMPLES=500`, below). This doesn't really affect the model's progress during training (it only has 32 parameters, and doesn't need much data to constrain these). Using fewer examples just ends training earlier (5min), but runs long enough to show that it is making progress in the validation logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8vuQpSLlBV2"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 25\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "NUM_EXAMPLES = len(x_train_tfcirc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJnNG-3JojiI"
      },
      "outputs": [],
      "source": [
        "x_train_tfcirc_sub = x_train_tfcirc[:NUM_EXAMPLES]\n",
        "y_train_hinge_sub = y_train_hinge[:NUM_EXAMPLES]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMSdgGC1GL7D"
      },
      "source": [
        "Training this model to convergence should achieve >85% accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ya9qP3KkojiM"
      },
      "outputs": [],
      "source": [
        "qnn_history = model.fit(x_train_tfcirc_sub,\n",
        "                        y_train_hinge_sub,\n",
        "                        batch_size=32,\n",
        "                        epochs=EPOCHS,\n",
        "                        verbose=1,\n",
        "                        validation_data=(x_val_tfcirc, y_val_hinge))\n",
        "print(\"Evaluating on Test\")\n",
        "qnn_results = model.evaluate(x_test_tfcirc, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qnn_results = model.evaluate(x_test_tfcirc, y_test)"
      ],
      "metadata": {
        "id": "uM5Sc2OrShOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ER7B7aaojiP"
      },
      "source": [
        "Note: The training accuracy reports the average over the epoch. The validation accuracy is evaluated at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model weights\n",
        "#model.save_weights(\"quantum_model_weights-20epochstestacc98.h5\")\n"
      ],
      "metadata": {
        "id": "9cvm_PQz3yLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#USE MODEL TO PREDICT"
      ],
      "metadata": {
        "id": "rEfE3P6UTwYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Image as IPImage\n",
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "import cirq\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "def upload_and_classify(model):\n",
        "    \"\"\"Upload an image file and classify it using the quantum model.\"\"\"\n",
        "    uploader = widgets.FileUpload(accept='image/*', multiple=False)\n",
        "    display(uploader)\n",
        "\n",
        "    def on_upload(change):\n",
        "        \"\"\"Process uploaded image.\"\"\"\n",
        "        uploaded_file = next(iter(uploader.value.values()))\n",
        "        image_data = uploaded_file['content']\n",
        "\n",
        "        image_path = \"/content/uploaded_image.jpg\"\n",
        "        with open(image_path, \"wb\") as f:\n",
        "            f.write(image_data)\n",
        "\n",
        "        print(\"\\nUploaded Image:\")\n",
        "        display(IPImage(image_path))\n",
        "\n",
        "        result, score = classify_image(model, image_path)\n",
        "        print(\"\\nðŸ” Final Classification Result:\", result)\n",
        "        print(\"ðŸ“Š Model Confidence Score:\", score)\n",
        "\n",
        "    uploader.observe(on_upload, names='value')\n",
        "\n",
        "def load_and_preprocess_image(image_path, image_size=(4, 4)):\n",
        "    \"\"\"Loads an image, converts to grayscale, resizes, and normalizes it.\"\"\"\n",
        "    image = Image.open(image_path).convert(\"L\")  # Convert to grayscale\n",
        "    image = image.resize(image_size)  # Resize to 4x4\n",
        "    image_array = np.array(image) / 255.0\n",
        "    return image_array\n",
        "\n",
        "\n",
        "def classify_image(model, image_path):\n",
        "    \"\"\"Takes an image file, processes it, and returns a classification result.\"\"\"\n",
        "    image = load_and_preprocess_image(image_path)\n",
        "    circuit = convert_to_circuit(image)\n",
        "    x_input = convert_circuit_to_tensor(circuit)\n",
        "\n",
        "    prediction = model(x_input)\n",
        "    score = prediction.numpy()[0][0]\n",
        "\n",
        "\n",
        "    class_names = tf.keras.utils.image_dataset_from_directory(\"/content/dataset/train\").class_names\n",
        "    print(\"Class Names:\", class_names)\n",
        "\n",
        "    if class_names[0] == \"crack\":\n",
        "        crack_label = -1\n",
        "        good_label = +1\n",
        "    else:\n",
        "        crack_label = +1\n",
        "        good_label = -1\n",
        "\n",
        "    scaled_score = 2 * score  # Expand range to [-2, 2]\n",
        "    if scaled_score > 1:\n",
        "        result = \"Good (No Crack)\"\n",
        "    else:\n",
        "        result = \"Crack Detected\"\n",
        "\n",
        "    # Print Model Output\n",
        "    print()\n",
        "    print(f\"Score: {score} | Classification: {result}\")\n",
        "\n",
        "    # Visualize Quantum Circuit\n",
        "    #print(\"\\nQuantum Circuit Representation:\")\n",
        "    #print(circuit)\n",
        "\n",
        "    return result, score\n",
        "\n",
        "\n",
        "upload_and_classify(model)\n"
      ],
      "metadata": {
        "id": "umg5QsDdTzPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8952YvuWGL7J"
      },
      "source": [
        "## 3. Classical neural network\n",
        "\n",
        "While the quantum neural network works for this simplified MNIST problem, a basic classical neural network can easily outperform a QNN on this task. After a single epoch, a classical neural network can achieve >98% accuracy on the holdout set.\n",
        "\n",
        "In the following example, a classical neural network is used for for the 3-6 classification problem using the entire 28x28 image instead of subsampling the image. This easily converges to nearly 100% accuracy of the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZofEHhLGL7L"
      },
      "outputs": [],
      "source": [
        "def create_classical_model():\n",
        "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(\n",
        "        tf.keras.layers.Conv2D(32, [3, 3],\n",
        "                               activation='relu',\n",
        "                               input_shape=(28, 28, 1)))\n",
        "    model.add(tf.keras.layers.Conv2D(64, [3, 3], activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_classical_model()\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiAJl7sZojiU"
      },
      "outputs": [],
      "source": [
        "# Reload training and testing datasets in original (28,28,1) size\n",
        "train_dataset_cnn = load_images(\"/content/dataset/train\", image_size=(28, 28))  # Use original size\n",
        "val_dataset_cnn = load_images(\"/content/dataset/val\", image_size=(28, 28))\n",
        "test_dataset_cnn = load_images(\"/content/dataset/test\", image_size=(28,28))\n",
        "\n",
        "# Convert to numpy arrays\n",
        "x_train_cnn, y_train_cnn = [], []\n",
        "for img, lbl in train_dataset_cnn:\n",
        "    x_train_cnn.extend(img.numpy())\n",
        "    y_train_cnn.extend(lbl.numpy())\n",
        "\n",
        "x_val_cnn, y_val_cnn = [], []\n",
        "for img, lbl in val_dataset_cnn:\n",
        "    x_val_cnn.extend(img.numpy())\n",
        "    y_val_cnn.extend(lbl.numpy())\n",
        "\n",
        "x_test_cnn, y_test_cnn = [], []\n",
        "for img, lbl in test_dataset_cnn:\n",
        "    x_test_cnn.extend(img.numpy())\n",
        "    y_test_cnn.extend(lbl.numpy())\n",
        "\n",
        "x_train_cnn, y_train_cnn = np.array(x_train_cnn), np.array(y_train_cnn)\n",
        "x_val_cnn, y_val_cnn = np.array(x_val_cnn), np.array(y_val_cnn)\n",
        "x_test_cnn, y_test_cnn = np.array(x_test_cnn), np.array(y_test_cnn)\n",
        "\n",
        "# training the CNN\n",
        "model.fit(x_train_cnn, y_train_cnn, batch_size=128, epochs=10, verbose=1, validation_data=(x_val_cnn, y_val_cnn))\n",
        "\n",
        "print(\"Evaluating on Test\")\n",
        "cnn_results = model.evaluate(x_test_cnn, y_test_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5-5BVJaojiZ"
      },
      "source": [
        "The above model has nearly 1.2M parameters. For a more fair comparison, try a 37-parameter model, on the subsampled images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70TOM6r-ojiZ",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "def create_fair_classical_model():\n",
        "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=(4, 4, 1)))\n",
        "    model.add(tf.keras.layers.Dense(2, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_fair_classical_model()\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA_Fx-8gojid"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train_bin,\n",
        "          y_train,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "          verbose=2,\n",
        "          validation_data=(x_val_bin, y_val))\n",
        "print(\"Evaluating on Test\")\n",
        "fair_nn_results = model.evaluate(x_test_bin, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH3mam7EGL7N"
      },
      "source": [
        "## 4. Comparison\n",
        "\n",
        "Higher resolution input and a more powerful model make this problem easy for the CNN. While a classical model of similar power (~32 parameters) trains to a similar accuracy in a fraction of the time. One way or the other, the classical neural network easily outperforms the quantum neural network. For classical data, it is difficult to beat a classical neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOMeN7pMGL7P"
      },
      "outputs": [],
      "source": [
        "qnn_accuracy = qnn_results[1]\n",
        "cnn_accuracy = cnn_results[1]\n",
        "fair_nn_accuracy = fair_nn_results[1]\n",
        "\n",
        "sns.barplot(x=[\"Quantum\", \"Classical, full\", \"Classical, fair\"],\n",
        "            y=[qnn_accuracy, cnn_accuracy, fair_nn_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v293vyE6CIJP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "mnist.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9 (main, Dec  7 2022, 13:47:07) [GCC 12.2.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}